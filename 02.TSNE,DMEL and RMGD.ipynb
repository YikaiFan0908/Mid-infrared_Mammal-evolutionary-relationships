{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39825dd4",
   "metadata": {},
   "source": [
    "Great differences in milk components and MIRS among different species of mammals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b4d475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import vstack, array, nan\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "sns.set_style(\"whitegrid\")\n",
    "from matplotlib import rcParams\n",
    "\n",
    "#MIRS\n",
    "mir_data_9=pd.read_csv('D://evolution/describe_train_test_9.csv',delimiter=',',encoding='unicode_escape')\n",
    "mir_data=mir_data.dropna()\n",
    "print(mir_data_9)\n",
    "config = {\n",
    "#     \"mathtext.fontset\":'Arial',\n",
    "    \"font.family\":'Arial',\n",
    "    \"font.serif\": ['Arial'],\n",
    "    # \"font.size\": 15,\n",
    "}\n",
    "rcParams.update(config)\n",
    "plt.figure(figsize=(20,10))\n",
    "selection_1=mir_data_9.iloc[0:30,list(range(3,800))]\n",
    "X1=selection_1.values\n",
    "X1=np.mean(selection_1).values\n",
    "X1=np.log10(1/X1)\n",
    "selection_2=mir_data_9.iloc[30:60,list(range(3,800))]\n",
    "X2=selection_2.values\n",
    "X2=np.mean(selection_2).values\n",
    "X2=np.log10(1/X2)\n",
    "selection_3=mir_data_9.iloc[60:90,list(range(3,800))]\n",
    "X3=selection_3.values\n",
    "X3=np.mean(selection_3).values\n",
    "X3=np.log10(1/X3)\n",
    "selection_4=mir_data_9.iloc[90:120,list(range(3,800))]\n",
    "X4=selection_4.values\n",
    "X4=np.mean(selection_4).values\n",
    "X4=np.log10(1/X4)\n",
    "selection_5=mir_data_9.iloc[120:150,list(range(3,800))]\n",
    "X5=selection_5.values\n",
    "X5=np.mean(selection_5).values\n",
    "X5=np.log10(1/X5)\n",
    "selection_6=mir_data_9.iloc[150:180,list(range(3,800))]\n",
    "X6=selection_6.values\n",
    "X6=np.mean(selection_6).values\n",
    "X6=np.log10(1/X6)\n",
    "selection_7=mir_data_9.iloc[180:210,list(range(3,800))]\n",
    "X7=selection_7.values\n",
    "X7=np.mean(selection_7).values\n",
    "X7=np.log10(1/X7)\n",
    "selection_8=mir_data_9.iloc[210:240,list(range(3,800))]\n",
    "X8=selection_8.values\n",
    "X8=np.mean(selection_8).values\n",
    "X8=np.log10(1/X8)\n",
    "selection_9=mir_data_9.iloc[240:270,list(range(3,800))]\n",
    "X9=selection_9.values\n",
    "X9=np.mean(selection_9).values\n",
    "X9=np.log10(1/X9)\n",
    "label_names = ['Holetein', 'simmental', 'jersey', 'buffalo', 'yak', 'goat', 'horse', 'camel','sheep','ass','Xinjiang Brown','pig']\n",
    "x = range(1,880,80)\n",
    "spectrum_index = np.linspace(1,797,797)\n",
    "plt.plot(spectrum_index[:],X1.T[:],color='r',label='Holstein',linewidth=2.5)\n",
    "plt.plot(spectrum_index[:],X2.T[:],color='g',label='Buffalo',linewidth=2.5)\n",
    "plt.plot(spectrum_index[:],X3.T[:],color='b',label='Yak',linewidth=2.5)\n",
    "plt.plot(spectrum_index[:],X4.T[:],color='m',label='Goat',linewidth=2.5)\n",
    "plt.plot(spectrum_index[:],X5.T[:],color='c',label='Horse',linewidth=2.5)\n",
    "plt.plot(spectrum_index[:],X6.T[:],color='orange',label='Camel',linewidth=2.5)\n",
    "plt.plot(spectrum_index[:],X7.T[:],color='deeppink',label='Sheep',linewidth=2.5)\n",
    "plt.plot(spectrum_index[:],X8.T[:],color='grey',label='Ass',linewidth=2.5)\n",
    "plt.plot(spectrum_index[:],X9.T[:],color='greenyellow',label='Pig',linewidth=2.5)\n",
    "\n",
    "\n",
    "# fat\n",
    "plt.text(60, 0.29, 'Fat I', fontsize=15, color='k',weight='bold')\n",
    "plt.text(213, 0.3, 'Fat II', fontsize=15, color='k',weight='bold')\n",
    "plt.text(480, 0.4, 'Fat III', fontsize=15, color='k',weight='bold')\n",
    "\n",
    "# lac\n",
    "plt.text(25, 0.46, 'Lactose I', fontsize=15, color='k',weight='bold')\n",
    "plt.text(98, 0.17, 'Lactose II', fontsize=15, color='k',weight='bold')\n",
    "\n",
    "# pro\n",
    "plt.text(135, 0.4, 'Protein', fontsize=15, color='k',weight='bold')\n",
    "\n",
    "plt.axvline(x=spectrum_index[174:175],linestyle='--',c='grey',linewidth=3)\n",
    "plt.axvline(x=spectrum_index[208:209],linestyle='--',c='grey',linewidth=3)\n",
    "plt.axvline(x=spectrum_index[533:534],linestyle='--',c='grey',linewidth=3)\n",
    "plt.axvline(x=spectrum_index[704:705],linestyle='--',c='grey',linewidth=3)\n",
    "\n",
    "plt.ylim(-0.6,0.9)\n",
    "plt.xlabel('Wave number/$\\mathregular{cm^{-1}}$',fontsize=30,weight='bold',labelpad=20)\n",
    "plt.ylabel('Absorbance',fontsize=30,weight='bold')\n",
    "plt.xticks(x, ('925.92','1234.56','1543.2','1851.84','2160.48','2469.12','2777.76','3086.4','3395.04','3703.68','4012.32'),fontsize=20,fontname='Arial',weight='bold')\n",
    "plt.yticks(fontsize=25,fontname='Arial',weight='bold')\n",
    "font1 = {'family':['Arial'],\n",
    "'weight' : 'bold',\n",
    "'size': 13,\n",
    "}\n",
    "plt.legend(prop=font1)\n",
    "\n",
    "\n",
    "plt.text(20, -0.4, 'Fingerprint region I', fontsize=17, color='k',weight='bold')\n",
    "plt.annotate('Water absorption region I', xy=(189, 0.7), xytext=(220,0.50), fontsize=18, arrowprops=dict(arrowstyle=\"->\", color=\"k\",linewidth=2),weight='bold')\n",
    "plt.text(320, -0.4, 'Fingerprint region II', fontsize=17, color='k',weight='bold')\n",
    "plt.text(538, 0.7, 'Water absorption region II', fontsize=17, color='k',weight='bold')\n",
    "plt.text(707, -0.4, 'Fingerprint region III', fontsize=17, color='k',weight='bold')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#TSNE\n",
    "mir_data=pd.read_csv('D://evolution/describe_train_test_9.csv',delimiter=',',encoding='unicode_escape')\n",
    "mir_data=mir_data.dropna()\n",
    "print(mir_data)\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import math\n",
    "from tkinter import _flatten\n",
    "\n",
    "for m in range(1):\n",
    "    selection=mir_data.iloc[:,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "    X=selection\n",
    "    X1=X.values\n",
    "    y=mir_data.iloc[:1203,1]\n",
    "    X_tsne = TSNE(n_components=3,random_state=0).fit_transform(X)\n",
    "    X_pca = PCA(n_components=3).fit_transform(X)\n",
    "\n",
    "\n",
    "    Holetein,simmental,jersey,buffalo,yak,goat,horse,camel,sheep,ass,Xinjiang_grey,pig=[],[],[],[],[],[],[],[],[],[],[],[]\n",
    "    def eucliDist(A,B):\n",
    "        return math.sqrt(sum([(a - b)**2 for(a,b)in zip(A,B)]))\n",
    "    label_types = [ 1, 2, 3, 4, 5, 6, 7, 8,9]\n",
    "    label_names = ['Holstein', 'Buffalo', 'Yak', 'Goat', 'Horse', 'Camel','Sheep','Ass','Pig']\n",
    "    markers = ['o', '^', 'd', '+', 'x','o', 's', 'd','+']\n",
    "    colors = ['r', 'g', 'b', 'm', 'c','orange','deeppink','grey','greenyellow']\n",
    "\n",
    "    ckpt_dir=\"images\"\n",
    "    if not os.path.exists(ckpt_dir):                                       \n",
    "        os.makedirs(ckpt_dir)\n",
    "\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    x_tsne = TSNE(n_components=2,init='pca',random_state=0).fit_transform(X1)\n",
    "    plt.figure(figsize=(12.5,10))\n",
    "    for label_type, label_name, marker, color in zip(label_types, label_names, markers, colors):\n",
    "        plt.scatter(x_tsne[y == label_type, 1], x_tsne[y == label_type, 0],marker=marker,\n",
    "                        label=label_name, c=color, s=200,alpha=0.7)\n",
    "    font1 = {'family':['Arial'],\n",
    "    'weight' : 'bold',\n",
    "    'size': 15,\n",
    "    }   \n",
    "    num1 = 1.01\n",
    "    num2 = 0.3\n",
    "    num3 = 3\n",
    "    num4 = 0\n",
    "    plt.legend(prop=font1,bbox_to_anchor=(num1, num2), loc=num3, borderaxespad=num4)\n",
    "\n",
    "    plt.xticks(fontsize=20,weight='bold')\n",
    "    plt.yticks(fontsize=20,weight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd162bf",
   "metadata": {},
   "source": [
    "DMEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5eb0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DMEL\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import urllib.request\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import vstack, array, nan\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, auc, roc_curve\n",
    "\n",
    "# Order\n",
    "evolution=pd.read_csv('D://evolution//20220516_species_classification_evolution_order.csv',delimiter=',',encoding='unicode_escape')\n",
    "selection=evolution.iloc[:,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "X=selection\n",
    "X1=X.values\n",
    "y=evolution.iloc[:,1]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X1, y,test_size=0.3, random_state=6)\n",
    "transfer = StandardScaler()\n",
    "x_train = transfer.fit_transform(x_train)\n",
    "x_test = transfer.transform(x_test)\n",
    "estimator = RandomForestClassifier(random_state=42)\n",
    "param_dict = {\"n_estimators\":[50], \"max_depth\":[8]}\n",
    "estimator = GridSearchCV(estimator, param_grid=param_dict,cv=10,n_jobs=1,scoring='roc_auc')\n",
    "estimator = estimator.fit(x_train, y_train)\n",
    "y_predict1 = estimator.predict(x_train)\n",
    "y_predict2 = estimator.predict(x_test)\n",
    "\n",
    "selection=mir_data.iloc[:,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "# selection=mir_data.iloc[:212,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "# selection=mir_data.iloc[212:397,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "# selection=mir_data.iloc[397:458,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "# selection=mir_data.iloc[458:607,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "# selection=mir_data.iloc[607:655,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "# selection=mir_data.iloc[655:682,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "# selection=mir_data.iloc[682:706,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "# selection=mir_data.iloc[706:738,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "# selection=mir_data.iloc[738:788,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "# selection=mir_data.iloc[788:864,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "# selection=mir_data.iloc[864:913,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "# selection=mir_data.iloc[913:916,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "# selection=mir_data.iloc[916:971,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "X1=selection.values\n",
    "# X1=(np.mean(selection).values).reshape(1,-1)\n",
    "X1 = transfer.transform(X1)\n",
    "y_predict3 = estimator.predict(X1)\n",
    "y_predict3 = np.array([np.argmax(i) for i in y_predict3])\n",
    "pro = estimator.predict_proba(X1)\n",
    "print(y_predict3,pro)\n",
    "score = estimator.score(x_test, y_test)\n",
    "print(score)\n",
    "\n",
    "report1 = classification_report(y_train, y_predict1, labels=[1,2], target_names=['Perissodactyla', 'Artiodactyla'])\n",
    "report2 = classification_report(y_test, y_predict2, labels=[1,2], target_names=['Perissodactyla', 'Artiodactyla'])\n",
    "print(report1,report2)\n",
    "\n",
    "kappa1=sklearn.metrics.cohen_kappa_score(y_train, y_predict1, labels=None, weights=None, sample_weight=None)\n",
    "print(kappa1)\n",
    "kappa2=sklearn.metrics.cohen_kappa_score(y_test, y_predict2, labels=None, weights=None, sample_weight=None)\n",
    "print(kappa2)\n",
    "\n",
    "def imshow(true,pre,label,title):\n",
    "    import the confusion_matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from matplotlib.colors import Normalize\n",
    "    plt.figure(figsize=(10,10))\n",
    "    matrixs = confusion_matrix(true,pre)\n",
    "    \n",
    "    plt.imshow(matrixs,cmap=plt.cm.Reds)\n",
    "    indices = range(len(matrixs))\n",
    "    \n",
    "    plt.xticks(indices,label,fontsize=18,weight='bold')\n",
    "    plt.yticks(indices,label,fontsize=18,weight='bold')\n",
    "    cb=plt.colorbar()\n",
    "    labels = cb.ax.yaxis.get_ticklabels()\n",
    "    [label.set_fontname('Arial') for label in labels]\n",
    "    [label.set_weight('bold') for label in labels]\n",
    "    cb.ax.tick_params(labelsize=28)\n",
    "\n",
    "    plt.xlabel('Predict label',fontsize=30,weight='bold',labelpad=20)\n",
    "    plt.ylabel('True label',fontsize=30,weight='bold')\n",
    "    plt.title(title,fontsize=30, pad=40,weight='bold')\n",
    "    for first_index in range(len(matrixs)):  \n",
    "        for second_index in range(len(matrixs[first_index])):\n",
    "            if first_index==second_index and first_index==1:\n",
    "                plt.text(first_index, second_index, matrixs[first_index][second_index],ha=\"center\",va=\"center\",c='w',fontsize=40,weight='bold')\n",
    "            else:\n",
    "                plt.text(first_index, second_index, matrixs[first_index][second_index],ha=\"center\",va=\"center\",c='k',fontsize=40,weight='bold')\n",
    "#     label = ['Holetein', 'simmental', 'jersey', 'buffalo', 'yak', 'goat', 'horse', 'camel','sheep','ass','Xinjiang Brown','pig']\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return plt\n",
    "\n",
    "label_1=['Perissodactyla', 'Artiodactyla']\n",
    "imshow(y_train, y_predict1,label_1,'Cross-validation result')\n",
    "imshow(y_test, y_predict2,label_1,'Predicted result')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Family\n",
    "evolution=pd.read_csv('D://evolution//20220516_species_classification_evolution_Family.csv',delimiter=',',encoding='unicode_escape')\n",
    "\n",
    "for m in range(1):\n",
    "    for n in range(1):\n",
    "        selection=evolution.iloc[10:,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "        X=selection\n",
    "        X1=X.values\n",
    "        y=evolution.iloc[10:,1]\n",
    "        X=Preprocessing('D1', X1)\n",
    "        x_train, x_test, y_train, y_test = train_test_split(X, y,test_size=0.3, random_state=6)\n",
    "        transfer = StandardScaler()\n",
    "        x_train = transfer.fit_transform(x_train)\n",
    "        x_test = transfer.transform(x_test)\n",
    "        estimator = RandomForestClassifier(random_state=42)\n",
    "        param_dict = {\"n_estimators\":[50], \"max_depth\":[8]}\n",
    "        estimator = GridSearchCV(estimator, param_grid=param_dict,cv=10,n_jobs=1,scoring='roc_auc')\n",
    "        estimator = estimator.fit(x_train, y_train)\n",
    "        y_predict1 = estimator.predict(x_train)\n",
    "        y_predict2 = estimator.predict(x_test)\n",
    "\n",
    "    #     selection=mir_data.iloc[:,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "    #     selection=mir_data.iloc[:212,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "    #     selection=mir_data.iloc[212:397,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "    #     selection=mir_data.iloc[397:458,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "    #     selection=mir_data.iloc[458:607,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "    #     selection=mir_data.iloc[607:655,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "    #     selection=mir_data.iloc[655:682,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "    #     selection=mir_data.iloc[682:706,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "    #     selection=mir_data.iloc[706:738,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "    #     selection=mir_data.iloc[738:788,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "    #     selection=mir_data.iloc[788:864,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "    #     selection=mir_data.iloc[864:913,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "    #     selection=mir_data.iloc[913:916,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "    #     selection=mir_data.iloc[916:971,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "        X1=selection.values\n",
    "\n",
    "        X1=(np.mean(selection).values).reshape(1,-1)\n",
    "        X1=Preprocessing('D1', X1)\n",
    "        X1 = transfer.transform(X1)\n",
    "        y_predict3 = estimator.predict(X1)\n",
    "        # y_predict3 = np.array([np.argmax(i) for i in y_predict3])\n",
    "        pro = estimator.predict_proba(X1)\n",
    "        print(y_predict3,pro)\n",
    "        score = estimator.score(x_test, y_test)\n",
    "        print(score)\n",
    "\n",
    "        report1 = classification_report(y_train, y_predict1, labels=[1,2], target_names=['camel', 'cattle'])\n",
    "        report2 = classification_report(y_test, y_predict2, labels=[1,2], target_names=['camel', 'cattle'])\n",
    "        print(report1,report2)\n",
    "        kappa1=sklearn.metrics.cohen_kappa_score(y_train, y_predict1, labels=None, weights=None, sample_weight=None)\n",
    "        print(kappa1)\n",
    "        kappa2=sklearn.metrics.cohen_kappa_score(y_test, y_predict2, labels=None, weights=None, sample_weight=None)\n",
    "        print(kappa2)\n",
    "    \n",
    "def imshow(true,pre,label,title):\n",
    "    # import the confusion_matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from matplotlib.colors import Normalize\n",
    "    plt.figure(figsize=(10,10))\n",
    "    matrixs = confusion_matrix(true,pre)\n",
    "    \n",
    "    plt.imshow(matrixs,cmap=plt.cm.Purples)\n",
    "    indices = range(len(matrixs))\n",
    "    \n",
    "    plt.xticks(indices,label,fontsize=20,weight='bold')\n",
    "    plt.yticks(indices,label,fontsize=20,weight='bold')\n",
    "    cb=plt.colorbar()\n",
    "    labels = cb.ax.yaxis.get_ticklabels()\n",
    "    [label.set_fontname('Arial') for label in labels]\n",
    "    [label.set_weight('bold') for label in labels]\n",
    "    cb.ax.tick_params(labelsize=30)\n",
    "#     cb.set_label(fontdict=font) #设置colorbar的标签字体及其大小\n",
    "\n",
    "    plt.xlabel('Predict label',fontsize=30,weight='bold',labelpad=20)\n",
    "    plt.ylabel('True label',fontsize=30,weight='bold')\n",
    "    plt.title(title,fontsize=30, pad=40,weight='bold')\n",
    "    for first_index in range(len(matrixs)):    #第几行\n",
    "        for second_index in range(len(matrixs[first_index])):    #第几列\n",
    "            if first_index==second_index and first_index==1:\n",
    "                plt.text(first_index, second_index, matrixs[first_index][second_index],ha=\"center\",va=\"center\",c='w',fontsize=40,weight='bold')\n",
    "            else:\n",
    "                plt.text(first_index, second_index, matrixs[first_index][second_index],ha=\"center\",va=\"center\",c='k',fontsize=40,weight='bold')\n",
    "# #     label = ['Holetein', 'simmental', 'jersey', 'buffalo', 'yak', 'goat', 'horse', 'camel','sheep','ass','Xinjiang Brown','pig']\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return plt\n",
    "\n",
    "label_2=['Camelidae','Bovidae']\n",
    "imshow(y_train, y_predict1,label_2,'Cross-validation result')\n",
    "imshow(y_test, y_predict2,label_2,'Predicted result')\n",
    "\n",
    "\n",
    "#Genus\n",
    "evolution=pd.read_csv('D://evolution//20220516_species_classification_evolution_genus.csv',delimiter=',',encoding='unicode_escape')\n",
    "# mir_data=mir_data.dropna()\n",
    "# print(evolution)\n",
    "\n",
    "for m in range(1):\n",
    "    for n in range(1):\n",
    "        selection=evolution.iloc[:,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "        X=selection\n",
    "        X=X.values\n",
    "        y=evolution.iloc[:,1]\n",
    "        X=Preprocessing('D1', X)\n",
    "        #划分数据集\n",
    "        x_train, x_test, y_train, y_test = train_test_split(X, y,test_size=0.3, random_state=6)\n",
    "        # 特征工程：标准化\n",
    "        transfer = StandardScaler()\n",
    "        x_train = transfer.fit_transform(x_train)\n",
    "        x_test = transfer.transform(x_test)\n",
    "\n",
    "        # #RF算法\n",
    "        estimator = RandomForestClassifier(random_state=42)\n",
    "        # 加入网格搜索与交叉验证\n",
    "        # 参数准备\n",
    "        param_dict = {\"n_estimators\":[49], \"max_depth\":[15]}\n",
    "        estimator = GridSearchCV(estimator, param_grid=param_dict,cv=10,n_jobs=1,scoring='roc_auc')\n",
    "        estimator = estimator.fit(x_train, y_train)\n",
    "\n",
    "        # 5）模型评估\n",
    "        # 方法1：直接比对真实值和预测值\n",
    "        y_predict1 = estimator.predict(x_train)\n",
    "        y_predict2 = estimator.predict(x_test)\n",
    "\n",
    "#         selection=mir_data.iloc[:,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "#         selection=mir_data.iloc[0:212,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "#         selection=mir_data.iloc[212:397,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "#         selection=mir_data.iloc[397:458,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "#         selection=mir_data.iloc[458:607,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "        selection=mir_data.iloc[607:655,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "#         selection=mir_data.iloc[655:682,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "    #     selection=mir_data.iloc[682:706,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "    #     selection=mir_data.iloc[706:738,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "#         selection=mir_data.iloc[738:788,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "    #     selection=mir_data.iloc[788:864,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "#         selection=mir_data.iloc[864:913,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "#         selection=mir_data.iloc[913:916,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "#         selection=mir_data.iloc[916:971,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "        X1=selection.values\n",
    "# #         X1=(np.mean(selection).values).reshape(1,-1)\n",
    "        X1=Preprocessing('D1', X1)\n",
    "        X1 = transfer.transform(X1)\n",
    "        y_predict3 = estimator.predict(X1)\n",
    "#         y_predict3 = np.array([np.argmax(i) for i in y_predict3])\n",
    "        pro = estimator.predict_proba(X1)\n",
    "        print(y_predict3,pro)\n",
    "        score = estimator.score(x_test, y_test)\n",
    "        print(score)\n",
    "        report1 = classification_report(y_train, y_predict1, labels=[1,2,3], target_names=['buffalo', 'cattle','goat'])\n",
    "        report2 = classification_report(y_test, y_predict2, labels=[1,2,3], target_names=['buffalo', 'cattle','goat'])\n",
    "        print(report1,report2)\n",
    "        kappa1=sklearn.metrics.cohen_kappa_score(y_train, y_predict1, labels=None, weights=None, sample_weight=None)\n",
    "        print(kappa1)\n",
    "        kappa2=sklearn.metrics.cohen_kappa_score(y_test, y_predict2, labels=None, weights=None, sample_weight=None)\n",
    "        print(kappa2)\n",
    "def imshow(true,pre,label,title):\n",
    "    # import the confusion_matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from matplotlib.colors import Normalize\n",
    "    plt.figure(figsize=(10,10))\n",
    "    matrixs = confusion_matrix(true,pre)\n",
    "    \n",
    "    plt.imshow(matrixs,cmap=plt.cm.Oranges)\n",
    "    indices = range(len(matrixs))\n",
    "    \n",
    "    plt.xticks(indices,label,fontsize=25,weight='bold')\n",
    "    plt.yticks(indices,label,fontsize=25,weight='bold')\n",
    "    cb=plt.colorbar()\n",
    "    labels = cb.ax.yaxis.get_ticklabels()\n",
    "    [label.set_fontname('Arial') for label in labels]\n",
    "    [label.set_weight('bold') for label in labels]\n",
    "    cb.ax.tick_params(labelsize=30)\n",
    "#     cb.set_label(fontdict=font) #设置colorbar的标签字体及其大小\n",
    "\n",
    "    plt.xlabel('Predict label',fontsize=30,weight='bold',labelpad=20)\n",
    "    plt.ylabel('True label',fontsize=30,weight='bold')\n",
    "    plt.title(title,fontsize=30, pad=40,weight='bold')\n",
    "    for first_index in range(len(matrixs)):    #第几行\n",
    "        for second_index in range(len(matrixs[first_index])):    #第几列\n",
    "            if first_index==second_index and first_index==1:\n",
    "                plt.text(first_index, second_index, matrixs[first_index][second_index],ha=\"center\",va=\"center\",c='w',fontsize=40,weight='bold')\n",
    "            else:\n",
    "                plt.text(first_index, second_index, matrixs[first_index][second_index],ha=\"center\",va=\"center\",c='k',fontsize=40,weight='bold')\n",
    "# #     label = ['Holetein', 'simmental', 'jersey', 'buffalo', 'yak', 'goat', 'horse', 'camel','sheep','ass','Xinjiang Brown','pig']\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return plt\n",
    "\n",
    "label_3=['Bubalus','Bos','Capra']\n",
    "imshow(y_train, y_predict1,label_3,'Cross-validation result')\n",
    "imshow(y_test, y_predict2,label_3,'Predicted result')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Subgenus\n",
    "evolution=pd.read_csv('D://evolution//20220516_species_classification_evolution_subgenus.csv',delimiter=',',encoding='unicode_escape')\n",
    "for m in range(50):\n",
    "    selection=evolution.iloc[:,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "    X=selection\n",
    "    X=X.values\n",
    "    y=evolution.iloc[:,1]\n",
    "    X=Preprocessing('D2', X)\n",
    "    #划分数据集\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y,test_size=0.3, random_state=6)\n",
    "    # 特征工程：标准化\n",
    "    transfer = StandardScaler()\n",
    "    x_train = transfer.fit_transform(x_train)\n",
    "    x_test = transfer.transform(x_test)\n",
    "\n",
    "    # #RF算法\n",
    "    estimator = RandomForestClassifier(random_state=42)\n",
    "    # 加入网格搜索与交叉验证\n",
    "    # 参数准备\n",
    "    param_dict = {\"n_estimators\":[50], \"max_depth\":[8]}\n",
    "    estimator = GridSearchCV(estimator, param_grid=param_dict,cv=10,n_jobs=1,scoring='roc_auc')\n",
    "    estimator = estimator.fit(x_train, y_train)\n",
    "\n",
    "    # 5）模型评估\n",
    "    # 方法1：直接比对真实值和预测值\n",
    "    y_predict1 = estimator.predict(x_train)\n",
    "    y_predict2 = estimator.predict(x_test)\n",
    "\n",
    "    selection=mir_data.iloc[:,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "#     selection=mir_data.iloc[0:212,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "#     selection=mir_data.iloc[212:397,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "#     selection=mir_data.iloc[397:458,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "#     selection=mir_data.iloc[458:607,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "#     selection=mir_data.iloc[607:655,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "#     selection=mir_data.iloc[655:682,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "#     selection=mir_data.iloc[682:706,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "#     selection=mir_data.iloc[706:738,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "#     selection=mir_data.iloc[738:788,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "#     selection=mir_data.iloc[788:864,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "#     selection=mir_data.iloc[864:913,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "#     selection=mir_data.iloc[913:916,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "#     selection=mir_data.iloc[916:971,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "    X1=selection.values\n",
    "#     X1=(np.mean(selection).values).reshape(1,-1)\n",
    "    X1=Preprocessing('D2', X1)\n",
    "    X1 = transfer.transform(X1)\n",
    "    y_predict3 = estimator.predict(X1)\n",
    "    # y_predict3 = np.array([np.argmax(i) for i in y_predict3])\n",
    "    pro = estimator.predict_proba(X1)\n",
    "    print(y_predict3,pro)\n",
    "\n",
    "    score = estimator.score(x_test, y_test)\n",
    "    print(score)\n",
    "    report1 = classification_report(y_train, y_predict1, labels=[1,2], target_names=['cattle', 'yak'])\n",
    "    report2 = classification_report(y_test, y_predict2, labels=[1,2], target_names=['cattle', 'yak'])\n",
    "    print(report1,report2)\n",
    "    kappa1=sklearn.metrics.cohen_kappa_score(y_train, y_predict1, labels=None, weights=None, sample_weight=None)\n",
    "    print(kappa1)\n",
    "    kappa2=sklearn.metrics.cohen_kappa_score(y_test, y_predict2, labels=None, weights=None, sample_weight=None)\n",
    "    print(kappa2)\n",
    "def imshow(true,pre,label,title):\n",
    "    # import the confusion_matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from matplotlib.colors import Normalize\n",
    "    plt.figure(figsize=(10,10))\n",
    "    matrixs = confusion_matrix(true,pre)\n",
    "    \n",
    "    plt.imshow(matrixs,cmap=plt.cm.Greens)\n",
    "    indices = range(len(matrixs))\n",
    "    \n",
    "    plt.xticks(indices,label,fontsize=25,weight='bold')\n",
    "    plt.yticks(indices,label,fontsize=25,weight='bold')\n",
    "    cb=plt.colorbar()\n",
    "    labels = cb.ax.yaxis.get_ticklabels()\n",
    "    [label.set_fontname('Arial') for label in labels]\n",
    "    [label.set_weight('bold') for label in labels]\n",
    "    cb.ax.tick_params(labelsize=25)\n",
    "#     cb.set_label(fontdict=font) #设置colorbar的标签字体及其大小\n",
    "\n",
    "    plt.xlabel('Predict label',fontsize=30,weight='bold',labelpad=20)\n",
    "    plt.ylabel('True label',fontsize=30,weight='bold')\n",
    "    plt.title(title,fontsize=30, pad=40,weight='bold')\n",
    "    for first_index in range(len(matrixs)):    #第几行\n",
    "        for second_index in range(len(matrixs[first_index])):    #第几列\n",
    "            if first_index==second_index and first_index==0:\n",
    "                plt.text(first_index, second_index, matrixs[first_index][second_index],ha=\"center\",va=\"center\",c='w',fontsize=40,weight='bold')\n",
    "            else:\n",
    "                plt.text(first_index, second_index, matrixs[first_index][second_index],ha=\"center\",va=\"center\",c='k',fontsize=40,weight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('D://evolution/Figure/Figure 2/subgenus_1.png',dpi=600)\n",
    "    plt.show()\n",
    "    return plt\n",
    "\n",
    "label_4=['Bibos','Poephagus']\n",
    "imshow(y_train, y_predict1,label_4,'Cross-validation result')\n",
    "imshow(y_test, y_predict2,label_4,'Predicted result')\n",
    "\n",
    "\n",
    "\n",
    "#Species\n",
    "evolution=pd.read_csv('D://evolution//20220516_species_classification_evolution_species.csv',delimiter=',',encoding='unicode_escape')\n",
    "for m in range(1):\n",
    "    selection=evolution.iloc[:,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "    X=selection\n",
    "    X=X.values\n",
    "    y=evolution.iloc[:,1]\n",
    "    X=Preprocessing('D1', X)\n",
    "    #划分数据集\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y,test_size=0.3, random_state=6)\n",
    "    # 特征工程：标准化\n",
    "    transfer = StandardScaler()\n",
    "    x_train = transfer.fit_transform(x_train)\n",
    "    x_test = transfer.transform(x_test)\n",
    "\n",
    "    # #RF算法\n",
    "    estimator = RandomForestClassifier(random_state=42)\n",
    "    # 加入网格搜索与交叉验证\n",
    "    # 参数准备\n",
    "    param_dict = {\"n_estimators\":[49], \"max_depth\":[15]}\n",
    "    estimator = GridSearchCV(estimator, param_grid=param_dict,cv=10,n_jobs=-1,scoring='roc_auc')\n",
    "    estimator = estimator.fit(x_train, y_train)\n",
    "\n",
    "    # 5）模型评估\n",
    "    # 方法1：直接比对真实值和预测值\n",
    "    y_predict1 = estimator.predict(x_train)\n",
    "    y_predict2 = estimator.predict(x_test)\n",
    "    \n",
    "#     selection=mir_data.iloc[:,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "#     selection=mir_data.iloc[0:458,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "#     selection=mir_data.iloc[0:212,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "#     selection=mir_data.iloc[212:397,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "#     selection=mir_data.iloc[397:458,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "#     selection=mir_data.iloc[458:607,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "#     selection=mir_data.iloc[607:655,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "#     selection=mir_data.iloc[655:682,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "#     selection=mir_data.iloc[682:706,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "#     selection=mir_data.iloc[706:738,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "#     selection=mir_data.iloc[738:788,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "#     selection=mir_data.iloc[788:864,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "#     selection=mir_data.iloc[864:913,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "#     selection=mir_data.iloc[913:916,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "#     selection=mir_data.iloc[916:971,list(range(3,163))+list(range(209,533))+list(range(705,800))]\n",
    "    X1=selection.values\n",
    "#     X1=(np.mean(selection).values).reshape(1,-1)\n",
    "    X1=Preprocessing('D1', X1)\n",
    "    X1 = transfer.transform(X1)\n",
    "    y_predict3 = estimator.predict(X1)\n",
    "    y_predict3 = np.array([np.argmax(i) for i in y_predict3])\n",
    "    pro = estimator.predict_proba(X1)\n",
    "    print(y_predict3,pro)\n",
    "    score = estimator.score(x_test, y_test)\n",
    "    print(score)\n",
    "    report1 = classification_report(y_train, y_predict1, labels=[1,2,3], target_names=['Holetein', 'simmental', 'jersey'])\n",
    "    report2 = classification_report(y_test, y_predict2, labels=[1,2,3], target_names=['Holetein', 'simmental', 'jersey'])\n",
    "    print(report1,report2)\n",
    "#     print(m)\n",
    "    \n",
    "    kappa1=sklearn.metrics.cohen_kappa_score(y_train, y_predict1, labels=None, weights=None, sample_weight=None)\n",
    "    print(kappa1)\n",
    "    kappa2=sklearn.metrics.cohen_kappa_score(y_test, y_predict2, labels=None, weights=None, sample_weight=None)\n",
    "    print(kappa2)\n",
    "def imshow(true,pre,label,title):\n",
    "    # import the confusion_matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from matplotlib.colors import Normalize\n",
    "    plt.figure(figsize=(10,10))\n",
    "    matrixs = confusion_matrix(true,pre)\n",
    "    \n",
    "    plt.imshow(matrixs,cmap=plt.cm.Greys)\n",
    "    indices = range(len(matrixs))\n",
    "    \n",
    "    plt.xticks(indices,label,fontsize=20,weight='bold')\n",
    "    plt.yticks(indices,label,fontsize=20,weight='bold')\n",
    "    cb=plt.colorbar()\n",
    "    labels = cb.ax.yaxis.get_ticklabels()\n",
    "    [label.set_fontname('Arial') for label in labels]\n",
    "    [label.set_weight('bold') for label in labels]\n",
    "    cb.ax.tick_params(labelsize=30)\n",
    "#     cb.set_label(fontdict=font) #设置colorbar的标签字体及其大小\n",
    "\n",
    "    plt.xlabel('Predict label',fontsize=30,weight='bold',labelpad=20)\n",
    "    plt.ylabel('True label',fontsize=30,weight='bold')\n",
    "    plt.title(title,fontsize=30, pad=40,weight='bold')\n",
    "    for first_index in range(len(matrixs)):    #第几行\n",
    "        for second_index in range(len(matrixs[first_index])):    #第几列\n",
    "            if first_index==second_index:\n",
    "                plt.text(first_index, second_index, matrixs[first_index][second_index],ha=\"center\",va=\"center\",c='w',fontsize=40,weight='bold')\n",
    "            else:\n",
    "                plt.text(first_index, second_index, matrixs[first_index][second_index],ha=\"center\",va=\"center\",c='k',fontsize=40,weight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('D://evolution/Figure/Figure 2/species_1.png',dpi=600)\n",
    "    plt.show()\n",
    "    return plt\n",
    "\n",
    "label_5=['Holstein', 'Simmental', 'Jersey']\n",
    "imshow(y_train, y_predict1,label_5,'Cross-validation result')\n",
    "imshow(y_test, y_predict2,label_5,'Predicted result')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5f094c",
   "metadata": {},
   "source": [
    "RMGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12841287",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "distance_train=pd.read_csv('D://evolution/distance_train.csv',delimiter=',',encoding='unicode_escape')\n",
    "distance_test=pd.read_csv('D://evolution/distance_test.csv',delimiter=',',encoding='unicode_escape')\n",
    "print(distance_train,distance_test)\n",
    "from pandas.core.frame import DataFrame\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import shuffle\n",
    "from numpy.linalg import matrix_rank as rank\n",
    "import numpy as np\n",
    "# PLSR\n",
    "for m in range(1):\n",
    "    X_train=distance_train.iloc[:,list(range(4,10))+list(range(18,23))+list(range(28,32))\n",
    "                            +list(range(37,45))+list(range(54,55))+list(range(58,62))\n",
    "                            +list(range(63,67))+list(range(70,73)) +list(range(76,77))\n",
    "                            +list(range(83,86))+list(range(94,98))\n",
    "                            +list(range(100,101))+list(range(108,109))+list(range(110,122))\n",
    "                            +list(range(128,134))+list(range(142,145))\n",
    "                            +list(range(155,161))+list(range(204,205))+list(range(221,228))+list(range(233,234))\n",
    "                            +list(range(235,241))+list(range(245,257))+list(range(271,276))\n",
    "                            +list(range(290,296))+list(range(312,321))+list(range(324,329))+list(range(332,338))\n",
    "                            +list(range(346,350))+list(range(358,366))+list(range(367,369))+list(range(372,376))\n",
    "                            +list(range(378,383))+list(range(389,398))+list(range(402,403))+list(range(407,408))\n",
    "                            +list(range(414,422))+list(range(429,433))+list(range(435,437))+list(range(444,450))\n",
    "                            +list(range(464,465))+list(range(468,470))+list(range(473,477))+list(range(478,483))+list(range(488,493))\n",
    "                            +list(range(494,497)) +list(range(498,512))+list(range(517,520))+list(range(522,524))+list(range(526,530))\n",
    "                            +list(range(708,715))+list(range(716,717))+list(range(718,724))+list(range(729,733))+list(range(744,747))\n",
    "                            +list(range(753,763))+list(range(768,770))\n",
    "                            +list(range(772,774))+list(range(775,777))+list(range(783,784))\n",
    "                            +list(range(785,794))+list(range(795,798))+list(range(799,800))]\n",
    "                            \n",
    "\n",
    "    X_test=distance_test.iloc[28:66,list(range(4,10))+list(range(18,23))+list(range(28,32))\n",
    "                            +list(range(37,45))+list(range(54,55))+list(range(58,62))\n",
    "                            +list(range(63,67))+list(range(70,73)) +list(range(76,77))\n",
    "                            +list(range(83,86))+list(range(94,98))\n",
    "                            +list(range(100,101)) +list(range(108,109))+list(range(110,122))\n",
    "                            +list(range(128,134))+list(range(142,145))\n",
    "                            +list(range(155,161))+list(range(204,205))+list(range(221,228))+list(range(233,234))\n",
    "                            +list(range(235,241))+list(range(245,257))+list(range(271,276))\n",
    "                            +list(range(290,296))+list(range(312,321))+list(range(324,329))+list(range(332,338))\n",
    "                            +list(range(346,350))+list(range(358,366))+list(range(367,369))+list(range(372,376))\n",
    "                            +list(range(378,383))+list(range(389,398))+list(range(402,403))+list(range(407,408))\n",
    "                            +list(range(414,422))+list(range(429,433))+list(range(435,437))+list(range(444,450))\n",
    "                            +list(range(464,465))+list(range(468,470))+list(range(473,477))+list(range(478,483))+list(range(488,493))\n",
    "                            +list(range(494,497)) +list(range(498,512))+list(range(517,520))+list(range(522,524))+list(range(526,530))\n",
    "                            +list(range(708,715))+list(range(716,717))+list(range(718,724))+list(range(729,733))+list(range(744,747))\n",
    "                            +list(range(753,763))+list(range(768,770))\n",
    "                            +list(range(772,774))+list(range(775,777))+list(range(783,784))\n",
    "                            +list(range(785,794))+list(range(795,798))+list(range(799,800))]\n",
    "    y_train=distance_train.iloc[:,2]\n",
    "    y_test=distance_test.iloc[28:66,2]\n",
    "    X_train=X_train.values\n",
    "    X_test=X_test.values\n",
    "    def SNV(data):\n",
    "        for i in range(data.shape[0]):\n",
    "            MEAN = np.mean(data[i])   # 计算平均值\n",
    "            STD = np.std(data[i],ddof=1)  # 标准偏差\n",
    "            data[i] = (data[i] - MEAN)/STD\n",
    "        return data\n",
    "    X_train=D1(X_train)\n",
    "    X_test=D1(X_test)\n",
    "    X_train=SNV(X_train)\n",
    "    X_test=SNV(X_test)\n",
    "    \n",
    "\n",
    "    transfer = StandardScaler()\n",
    "#     transfer = MinMaxScaler()\n",
    "    X_train=transfer.fit_transform(X_train)\n",
    "    X_test=transfer.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "    pls_model_setup = PLSRegression(scale=True)\n",
    "    param_grid = {'n_components': range(14,15)} \n",
    "    gsearch = GridSearchCV(pls_model_setup, param_grid,cv=10)\n",
    "    pls_model = gsearch.fit(X_train, y_train)\n",
    "    y_pred2 = pls_model.predict(X_train)\n",
    "    y_pred2=y_pred2.flatten()\n",
    "    y_pred = pls_model.predict(X_test)\n",
    "    y_pred=y_pred.flatten()\n",
    "    print(y_pred)\n",
    "    \n",
    "    r2_tra=float(1 - sum((y_train - y_pred2) ** 2) / sum((y_train - y_train.mean()) ** 2))\n",
    "    rmse_tra=float((sum((y_train - y_pred2) ** 2) / len(y_train)) ** 0.5)\n",
    "\n",
    "    r2_pre=float(1 - sum((y_test - y_pred) ** 2) / sum((y_test - y_test.mean()) ** 2))\n",
    "    rmse_pre=float((sum((y_test - y_pred) ** 2) / len(y_test)) ** 0.5)\n",
    "\n",
    "    print('Trian：',r2_tra** 0.5,rmse_tra)\n",
    "    print('Test：',r2_pre** 0.5,rmse_pre)\n",
    "\n",
    "def fit(data_x, data_y):\n",
    "    m = len(data_y)\n",
    "    x_bar = np.mean(data_x)\n",
    "    sum_yx = 0\n",
    "    sum_x2 = 0\n",
    "    sum_delta = 0\n",
    "    for i in range(m):\n",
    "        x = data_x[i]\n",
    "        y = data_y[i]\n",
    "        sum_yx += y * (x - x_bar)\n",
    "        sum_x2 += x ** 2\n",
    "    # 根据公式计算w\n",
    "    w = sum_yx / (sum_x2 - m * (x_bar ** 2))\n",
    "\n",
    "    for i in range(m):\n",
    "        x = data_x[i]\n",
    "        y = data_y[i]\n",
    "        sum_delta += (y - w * x)\n",
    "    b = sum_delta / m\n",
    "    return w, b\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(11,10))\n",
    "plt.xlabel(\"true_genetic distance\",fontsize=15)\n",
    "plt.ylabel(\"pre_genetic distance\",fontsize=15)\n",
    "\n",
    "\n",
    "# w1, b1 = fit(y_train.values,y_pred2)\n",
    "# print(w1,b1)\n",
    "# pred2_y = w1 * y_train.values + b1\n",
    "plt.scatter(y_train.values,y_pred2,color='b')\n",
    "# plt.plot(y_train.values, pred2_y, c='b', label='R=0.8822')\n",
    "plt.plot(plt.xlim(),plt.ylim(), c='b',label=\"R=0.9994\")\n",
    "\n",
    "\n",
    "plt.scatter(y_test.values,y_pred,color='orange',label=\"test\",marker='^')\n",
    "plt.plot(plt.xlim(),plt.ylim(), c='orange',label=\"R=0.9603\")\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.legend(fontsize=15)\n",
    "\n",
    "plt.subplot(322)\n",
    "plt.xlabel(\"true_genetic distance\",fontsize=15)\n",
    "plt.ylabel(\"true_genetic distance\",fontsize=15)\n",
    "plt.scatter(y_train,y_pred2,color='b',label=\"train\")\n",
    "plt.scatter(y_test,y_pred,color='orange',label=\"test\",marker='^')\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.legend(loc =2,fontsize=15)\n",
    "\n",
    "\n",
    "plt.subplot(323)\n",
    "plt.xlabel(\"Reference_genetic distance\",fontsize=35,weight='bold',labelpad=20)\n",
    "plt.ylabel(\"Pre_genetic distance\",fontsize=35,weight='bold',labelpad=20)\n",
    "plt.scatter(y_train.values,y_pred2,color='r',marker='^',s=150)\n",
    "plt.plot(plt.xlim(),plt.ylim(), c='k',label=\"R=0.9992\")\n",
    "plt.xticks(fontsize=25,weight='bold',rotation=45)\n",
    "plt.yticks(fontsize=25,weight='bold')\n",
    "font1 = {'family':['Arial'],\n",
    "'weight' : 'bold',\n",
    "'size': 30,\n",
    "}\n",
    "plt.legend(prop=font1)\n",
    "plt.tight_layout()\n",
    "print(y_train.values,y_pred2)\n",
    "plt.subplot(324)\n",
    "plt.xlabel(\"Reference_genetic distance\",fontsize=35,weight='bold',labelpad=20)\n",
    "plt.ylabel(\"Pre_genetic distance\",fontsize=35,weight='bold',labelpad=20)\n",
    "# w1, b1 = fit(y_test.values,y_pred)\n",
    "# pred_y = w1 * y_test.values + b1\n",
    "plt.scatter(y_test.values,y_pred,color='orange',marker='^',s=150)\n",
    "# plt.plot(y_test.values, pred_y, c='r', label='R=0.8888')\n",
    "plt.plot(plt.xlim(-0.025,0.2),plt.ylim(-0.025,0.2), c='k',label=\"R=0.9470\")\n",
    "plt.xticks(fontsize=25,weight='bold',rotation=45)\n",
    "plt.yticks(fontsize=25,weight='bold')\n",
    "font1 = {'family':['Arial'],\n",
    "'weight' : 'bold',\n",
    "'size': 30,\n",
    "}\n",
    "plt.legend(prop=font1)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4970ab95",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eff0c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import pywt\n",
    "\n",
    "def MMS(data):\n",
    "    \"\"\"\n",
    "       :param data: raw spectrum data, shape (n_samples, n_features)\n",
    "       :return: data after MinMaxScaler :(n_samples, n_features)\n",
    "       \"\"\"\n",
    "    return MinMaxScaler().fit_transform(data)\n",
    "\n",
    "\n",
    "def SS(data):\n",
    "    \"\"\"\n",
    "        :param data: raw spectrum data, shape (n_samples, n_features)\n",
    "       :return: data after StandScaler :(n_samples, n_features)\n",
    "       \"\"\"\n",
    "    return StandardScaler().fit_transform(data)\n",
    "\n",
    "\n",
    "def CT(data):\n",
    "    \"\"\"\n",
    "       :param data: raw spectrum data, shape (n_samples, n_features)\n",
    "       :return: data after MeanScaler :(n_samples, n_features)\n",
    "       \"\"\"\n",
    "    for i in range(data.shape[0]):\n",
    "        MEAN = np.mean(data[i])\n",
    "        data[i] = data[i] - MEAN\n",
    "    return data\n",
    "\n",
    "\n",
    "def SNV(data):\n",
    "    \"\"\"\n",
    "        :param data: raw spectrum data, shape (n_samples, n_features)\n",
    "       :return: data after SNV :(n_samples, n_features)\n",
    "    \"\"\"\n",
    "    m = data.shape[0]\n",
    "    n = data.shape[1]\n",
    "    print(m, n)  #\n",
    "    # 求标准差\n",
    "    data_std = np.std(data, axis=1)  # 每条光谱的标准差\n",
    "    # 求平均值\n",
    "    data_average = np.mean(data, axis=1)  # 每条光谱的平均值\n",
    "    # SNV计算\n",
    "    data_snv = [[((data[i][j] - data_average[i]) / data_std[i]) for j in range(n)] for i in range(m)]\n",
    "    return  np.array(data_snv)\n",
    "\n",
    "\n",
    "\n",
    "def MA(data, WSZ=11):\n",
    "    \"\"\"\n",
    "       :param data: raw spectrum data, shape (n_samples, n_features)\n",
    "       :param WSZ: int\n",
    "       :return: data after MA :(n_samples, n_features)\n",
    "    \"\"\"\n",
    "\n",
    "    for i in range(data.shape[0]):\n",
    "        out0 = np.convolve(data[i], np.ones(WSZ, dtype=int), 'valid') / WSZ # WSZ是窗口宽度，是奇数\n",
    "        r = np.arange(1, WSZ - 1, 2)\n",
    "        start = np.cumsum(data[i, :WSZ - 1])[::2] / r\n",
    "        stop = (np.cumsum(data[i, :-WSZ:-1])[::2] / r)[::-1]\n",
    "        data[i] = np.concatenate((start, out0, stop))\n",
    "    return data\n",
    "\n",
    "def SG(data, w=11, p=2):\n",
    "    \"\"\"\n",
    "       :param data: raw spectrum data, shape (n_samples, n_features)\n",
    "       :param w: int\n",
    "       :param p: int\n",
    "       :return: data after SG :(n_samples, n_features)\n",
    "    \"\"\"\n",
    "    return signal.savgol_filter(data, w, p)\n",
    "\n",
    "\n",
    "def D1(data):\n",
    "    \"\"\"\n",
    "       :param data: raw spectrum data, shape (n_samples, n_features)\n",
    "       :return: data after First derivative :(n_samples, n_features)\n",
    "    \"\"\"\n",
    "    n, p = data.shape\n",
    "    Di = np.ones((n, p - 1))\n",
    "    for i in range(n):\n",
    "        Di[i] = np.diff(data[i])\n",
    "    return Di\n",
    "\n",
    "\n",
    "def D2(data):\n",
    "    \"\"\"\n",
    "       :param data: raw spectrum data, shape (n_samples, n_features)\n",
    "       :return: data after second derivative :(n_samples, n_features)\n",
    "    \"\"\"\n",
    "    data = deepcopy(data)\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        data = data.values\n",
    "    temp2 = (pd.DataFrame(data)).diff(axis=1)\n",
    "    temp3 = np.delete(temp2.values, 0, axis=1)\n",
    "    temp4 = (pd.DataFrame(temp3)).diff(axis=1)\n",
    "    spec_D2 = np.delete(temp4.values, 0, axis=1)\n",
    "    return spec_D2\n",
    "\n",
    "\n",
    "def DT(data):\n",
    "    \"\"\"\n",
    "       :param data: raw spectrum data, shape (n_samples, n_features)\n",
    "       :return: data after DT :(n_samples, n_features)\n",
    "    \"\"\"\n",
    "    lenth = data.shape[1]\n",
    "    x = np.asarray(range(lenth), dtype=np.float32)\n",
    "    out = np.array(data)\n",
    "    l = LinearRegression()\n",
    "    for i in range(out.shape[0]):\n",
    "        l.fit(x.reshape(-1, 1), out[i].reshape(-1, 1))\n",
    "        k = l.coef_\n",
    "        b = l.intercept_\n",
    "        for j in range(out.shape[1]):\n",
    "            out[i][j] = out[i][j] - (j * k + b)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def MSC(data):\n",
    "    \"\"\"\n",
    "       :param data: raw spectrum data, shape (n_samples, n_features)\n",
    "       :return: data after MSC :(n_samples, n_features)\n",
    "    \"\"\"\n",
    "    n, p = data.shape\n",
    "    msc = np.ones((n, p))\n",
    "\n",
    "    for j in range(n):\n",
    "        mean = np.mean(data, axis=0)\n",
    "\n",
    "    # 线性拟合\n",
    "    for i in range(n):\n",
    "        y = data[i, :]\n",
    "        l = LinearRegression()\n",
    "        l.fit(mean.reshape(-1, 1), y.reshape(-1, 1))\n",
    "        k = l.coef_\n",
    "        b = l.intercept_\n",
    "        msc[i, :] = (y - b) / k\n",
    "    return msc\n",
    "\n",
    "\n",
    "def wave(data):\n",
    "    \"\"\"\n",
    "       :param data: raw spectrum data, shape (n_samples, n_features)\n",
    "       :return: data after wave :(n_samples, n_features)\n",
    "    \"\"\"\n",
    "    data = deepcopy(data)\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        data = data.values\n",
    "    def wave_(data):\n",
    "        w = pywt.Wavelet('db8')  # 选用Daubechies8小波\n",
    "        maxlev = pywt.dwt_max_level(len(data), w.dec_len)\n",
    "        coeffs = pywt.wavedec(data, 'db8', level=maxlev)\n",
    "        threshold = 0.04\n",
    "        for i in range(1, len(coeffs)):\n",
    "            coeffs[i] = pywt.threshold(coeffs[i], threshold * max(coeffs[i]))\n",
    "        datarec = pywt.waverec(coeffs, 'db8')\n",
    "        return datarec\n",
    "\n",
    "    tmp = None\n",
    "    for i in range(data.shape[0]):\n",
    "        if (i == 0):\n",
    "            tmp = wave_(data[i])\n",
    "        else:\n",
    "            tmp = np.vstack((tmp, wave_(data[i])))\n",
    "\n",
    "    return tmp\n",
    "\n",
    "def Preprocessing(method, data):\n",
    "\n",
    "    if method == \"None\":\n",
    "        data = data\n",
    "    elif method == 'MMS':\n",
    "        data = MMS(data)\n",
    "    elif method == 'SS':\n",
    "        data = SS(data)\n",
    "    elif method == 'CT':\n",
    "        data = CT(data)\n",
    "    elif method == 'SNV':\n",
    "        data = SNV(data)\n",
    "    elif method == 'MA':\n",
    "        data = MA(data)\n",
    "    elif method == 'SG':\n",
    "        data = SG(data)\n",
    "    elif method == 'MSC':\n",
    "        data = MSC(data)\n",
    "    elif method == 'D1':\n",
    "        data = D1(data)\n",
    "    elif method == 'D2':\n",
    "        data = D2(data)\n",
    "    elif method == 'DT':\n",
    "        data = DT(data)\n",
    "    elif method == 'WAVE':\n",
    "        data = wave(data)\n",
    "    else:\n",
    "        print(\"no this method of preprocessing!\")\n",
    "\n",
    "    return data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
